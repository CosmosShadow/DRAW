# coding: utf-8

import tensorflow as tf
from tensorflow.examples.tutorials import mnist
import numpy as np
import os

save_path = 'output/checkpoint.ckpt'

## MODEL PARAMETERS ## 

A, B = 28, 28 # image width,height
img_size = B*A # the canvas size
enc_size = 256 # number of hidden units / output size in LSTM
dec_size = 256
read_n = 5 # read glimpse grid width/height
write_n = 5 # write glimpse grid width/height
read_size = 2*read_n*read_n if ReadAtten else 2*img_size
write_size = write_n*write_n if WriteAtten else img_size
z_size = 10 # QSampler output size
T = 10 # MNIST generation sequence length
batch_size = 128
train_iters = 10000
learning_rate = 1e-3 # learning rate for optimizer
eps = 1e-8 # epsilon for numerical stability

## BUILD MODEL ## 

DO_SHARE=None # workaround for variable_scope(reuse=True)

ReadAtten = True
WriteAtten = True

class DRAW(object):
	def __init__(self, scope, ReadAtten, WriteAtten):
		self.x = tf.placeholder(tf.float32,shape=(batch_size,img_size)) # input (batch_size * img_size)
		e = tf.random_normal((batch_size,z_size), mean=0, stddev=1) # Qsampler noise
		lstm_enc = tf.nn.rnn_cell.LSTMCell(enc_size, state_is_tuple=True) # encoder Op
		lstm_dec = tf.nn.rnn_cell.LSTMCell(dec_size, state_is_tuple=True) # decoder Op
		read = read_attn if ReadAtten else read_no_attn
		write = write_atten if WriteAtten else write_no_attn

		# 状态
		cs = [0] * T # sequence of canvases
		mus, logsigmas, sigmas=[0]*T, [0]*T, [0]*T # gaussian params generated by SampleQ. We will need these for computing loss.
		# initial states
		h_dec_prev = tf.zeros((batch_size, dec_size))
		enc_state = lstm_enc.zero_state(batch_size, tf.float32)
		dec_state = lstm_dec.zero_state(batch_size, tf.float32)

		# reconstruction term appears to have been collapsed down to a single scalar value (rather than one per item in minibatch)
		x_recons = tf.nn.sigmoid(cs[-1])

		# after computing binary cross entropy,  sum across features then take the mean of those sums across minibatches
		Lx = tf.reduce_sum(binary_crossentropy(x, x_recons), 1) # reconstruction term
		self.Lx = tf.reduce_mean(Lx)

		kl_terms = [0] * T
		for t in range(T):
			mu2 = tf.square(mus[t])
			sigma2 = tf.square(sigmas[t])
			logsigma = logsigmas[t]
			kl_terms[t] = 0.5 * tf.reduce_sum(mu2+sigma2-2*logsigma, 1) - T*.5 # each kl term is (1xminibatch)
		KL = tf.add_n(kl_terms) # this is 1xminibatch,  corresponding to summing kl_terms from 1:T
		Lz = tf.reduce_mean(KL) # average over minibatches

		self.cost = self.Lx + self.Lz

## DRAW MODEL ## 

# construct the unrolled computational graph
for t in range(T):
	c_prev = tf.zeros((batch_size, img_size)) if t==0 else cs[t-1]
	x_hat = x - tf.sigmoid(c_prev) # error image
	r = read(x, x_hat, h_dec_prev)
	h_enc, enc_state = encode(enc_state, tf.concat(1, [r, h_dec_prev]))
	z, mus[t], logsigmas[t], sigmas[t] = sampleQ(h_enc)
	h_dec, dec_state = decode(dec_state, z)
	cs[t] = c_prev + write(h_dec) # store results
	h_dec_prev = h_dec
	DO_SHARE = True # from now on,  share variables

## LOSS FUNCTION ## 

def linear(x,output_dim):
	w=tf.get_variable("w", [x.get_shape()[1], output_dim]) 
	b=tf.get_variable("b", [output_dim], initializer=tf.constant_initializer(0.0))
	return tf.matmul(x,w)+b

def filterbank(gx, gy, sigma2, delta, N):
	grid_i = tf.reshape(tf.cast(tf.range(N), tf.float32), [1, -1])
	mu_x = gx + (grid_i - N / 2 - 0.5) * delta # eq 19
	mu_y = gy + (grid_i - N / 2 - 0.5) * delta # eq 20
	a = tf.reshape(tf.cast(tf.range(A), tf.float32), [1, 1, -1])
	b = tf.reshape(tf.cast(tf.range(B), tf.float32), [1, 1, -1])
	mu_x = tf.reshape(mu_x, [-1, N, 1])
	mu_y = tf.reshape(mu_y, [-1, N, 1])
	sigma2 = tf.reshape(sigma2, [-1, 1, 1])
	Fx = tf.exp(-tf.square((a - mu_x) / (2*sigma2))) # 2*sigma2?
	Fy = tf.exp(-tf.square((b - mu_y) / (2*sigma2))) # batch x N x B
	# normalize, sum over A and B dims
	Fx = Fx/tf.maximum(tf.reduce_sum(Fx, 2, keep_dims=True), eps)
	Fy = Fy/tf.maximum(tf.reduce_sum(Fy, 2, keep_dims=True), eps)
	return Fx, Fy

def attn_window(scope, h_dec, N):
	with tf.variable_scope(scope, reuse=DO_SHARE):
		params = linear(h_dec, 5)
	gx_, gy_, log_sigma2, log_delta, log_gamma = tf.split(1, 5, params)
	gx = (A+1)/2*(gx_+1)
	gy = (B+1)/2*(gy_+1)
	sigma2 = tf.exp(log_sigma2)
	delta = (max(A, B)-1)/(N-1)*tf.exp(log_delta) # batch x N
	return filterbank(gx, gy, sigma2, delta, N) + (tf.exp(log_gamma), )

## READ ## 
def read_no_attn(x, x_hat, h_dec_prev):
	return tf.concat(1, [x, x_hat])

def filter_img(img, Fx, Fy, gamma, N):
	Fxt = tf.transpose(Fx, perm = [0, 2, 1])
	img = tf.reshape(img, [-1, B, A])
	glimpse = tf.batch_matmul(Fy, tf.batch_matmul(img, Fxt))
	glimpse = tf.reshape(glimpse, [-1, N*N])
	return glimpse * tf.reshape(gamma, [-1,1])

def read_attn(x, x_hat, h_dec_prev):
	Fx, Fy, gamma = attn_window("read", h_dec_prev, read_n)
	x = filter_img(x, Fx, Fy, gamma, read_n) # batch x (read_n*read_n)
	x_hat = filter_img(x_hat, Fx, Fy, gamma, read_n)
	return tf.concat(1, [x, x_hat]) # concat along feature axis



## ENCODE ## 
def encode(state, input):
	"""
	run LSTM
	state = previous encoder state
	input = cat(read, h_dec_prev)
	returns: (output, new_state)
	"""
	with tf.variable_scope("encoder", reuse=DO_SHARE):
		return lstm_enc(input, state)

## Q-SAMPLER (VARIATIONAL AUTOENCODER) ##

def sampleQ(h_enc):
	"""
	Samples Zt ~ normrnd(mu,sigma) via reparameterization trick for normal dist
	mu is (batch,z_size)
	"""
	with tf.variable_scope("mu", reuse=DO_SHARE):
		mu = linear(h_enc, z_size)
	with tf.variable_scope("sigma", reuse=DO_SHARE):
		logsigma = linear(h_enc, z_size)
		sigma = tf.exp(logsigma)
	return (mu + sigma*e, mu, logsigma, sigma)

## DECODER ## 
def decode(state,input):
	with tf.variable_scope("decoder",reuse=DO_SHARE):
		return lstm_dec(input, state)

## WRITER ## 
def write_no_attn(h_dec):
	with tf.variable_scope("write", reuse=DO_SHARE):
		return linear(h_dec, img_size)

def write_atten(h_dec):
	with tf.variable_scope("writeW",reuse=DO_SHARE):
		w = linear(h_dec, write_size) # batch x (write_n*write_n)
	N = write_n
	w = tf.reshape(w, [batch_size, N, N])
	Fx, Fy, gamma = attn_window("write", h_dec, write_n)
	Fyt = tf.transpose(Fy, perm = [0, 2, 1])
	wr = tf.batch_matmul(Fyt, tf.batch_matmul(w, Fx))
	wr = tf.reshape(wr, [batch_size, B*A])
	return wr * tf.reshape(1.0/gamma, [-1, 1])

def binary_crossentropy(t, o):
	return -(t*tf.log(o+eps) + (1.0-t)*tf.log(1.0-o+eps))



